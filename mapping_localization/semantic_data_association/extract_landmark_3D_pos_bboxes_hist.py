from __future__ import (print_function, division, absolute_import)
import pickle
import cv2
import numpy as np
import glob
import sys
import transforms3d as trans3d
import os
from scpye.improc.image_processing import enhance_contrast
from scpye.track.assignment import hungarian_assignment
from scpye.track.bounding_box import (bboxes_assignment_cost, extract_bbox)
from scpye.track.fruit_track import FruitTrack
from scpye.track.optical_flow import (calc_optical_flow, calc_average_flow)
from scpye.utils.drawing import (Colors, draw_bboxes, draw_optical_flows,
                                 draw_text, draw_bboxes_matches, draw_line, draw_bbox_centers)
from scpye.track.bounding_box import (bbox_center, shift_bbox)
import time
import copy

def extract_landmark_3D_pos_bboxes_hist(data_dir_pre = '..'):
    visualize_projection_results = True
    false_case = 0
    duplicate_reconstructed_tracks = 0

    # TODO: counted_fruits_and_last_frame_whole_list.pkl no longer useful
    # with open('counted_fruits_and_last_frame_whole_list.pkl', 'rb') as input...

    # valid_points is a list of points containing valid_point 's index and corresponding frame number
    valid_points = np.load(data_dir_pre+'/generated_docs_this_run/valid_points.npy', allow_pickle = True)

    with open(data_dir_pre + '/image_features_bbox_dict.pkl', 'rb') as input:
        # generated by build_semantic_feature_matches.py
        # img_features_dict is in the form of: key: image frame index, value: a list with features and their bboxes, inside every element of this list is a sub-list, where the first element is feature coordinate in the image plane, the second element is the bbox x,y,w,h
        img_features_dict = pickle.load(input)

    fruit_bboxes_trackid_frame_list = []
    # TODO: new feature added: associate the image_features_dict with corresponding track id!!!
    for fr_idx, feature_bboxes_track_id in sorted(img_features_dict.items()):
        # for feature_bbox in feature_bboxes:[feature_bbox[0],feature_bbox[1]]
        #  fruit_bboxes_trackid_frame_list is a list, element in it is also a list, in which the first element is  [[array(xc,yc)],array([x,y,w,h])], track_id] and the second element is frame number, e.g., frame0000
        fr_idx_str = 'frame%04d' %fr_idx
        fruit_bboxes_trackid_frame_list.append([feature_bboxes_track_id, fr_idx_str])

    # 3D point list with one line of data per point:
    #   POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)
    # use three_dim_pts_ind_pos_dict to record the 3D points index, X, Y, Z as a dictionary, key is: POINT3D_ID, element is: [X, Y, Z]
    three_dim_pts_ind_pos_dict = {}
    with open(data_dir_pre +'/generated_docs_this_run/points3D.txt') as f:
        # Image list with two lines of data per image:
        #   IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID(use this image_id[ind][-1] to extract information we need!!!ID-1 = frame number!!!), NAME
        #   POINTS2D[] as (X, Y, POINT3D_ID)
        lines=f.readlines()
        ind = 0
        for line in lines:
            # skip the comments

            if line[0] == '#':
                continue
            else:
                #only need first four: POINT3D_ID, X, Y, Z
                pt_info_temp = np.fromstring(line, dtype=float, sep=' ')
                three_dim_pts_ind_pos_dict[pt_info_temp[0]] = pt_info_temp[1:4]

    print('total number of reconstructed 3D points are:', len(three_dim_pts_ind_pos_dict))

    # fruit_3D_pos_bboxes_hist_dict: key is 3D point index, value is a dictionary: {'3Dpos':fruit_3D_loc, 'frame_idx': [frame_ind] (order: small to large), '2Dpos_bbox':fruit}, which contains fruits' 3D position, frame index where it appears (a list of integers) and corresponding frame's 2D_position_and_bbox (a list where each element is another list: [array(x_center, y_center),array(bbox)])
    fruit_3D_pos_bboxes_hist_dict = {}
    frame_points = []
    frame_num_strs = []
    for valid_point in valid_points:
        frame_points.append(valid_point[0])
        # the actual image frame index
        frame_num_str_temp = 'frame%04d' % (valid_point[1])
        frame_num_strs.append(frame_num_str_temp)

    num_frames = len(frame_num_strs)

    pos_area_fridx_bbox_of_fruits = []

    num_of_fruits_no_corr_3D_point = {}
    total_num_of_fruits_no_corr_3D_point = 0

    # This dictonary records the correspondences between track id and its reconstructed 3D points. Every 3D point instance (useful for computing weighted average, may be the same point repeated for multiple times ) will be recorded.
    track_id_3D_point_dict = {}


    # frame_num_corr_pos_of_fruits = []
    start_loop = time.time()
    for element in fruit_bboxes_trackid_frame_list:
        if element[0]== None or element[0] ==[] or element[1] == None or element[1] == []:
            print('fruits_frame_list element is empty!')
            continue
        # element in list fruits is: [array(x_center, y_center),array(bbox), track_id]
        fruits_and_trackids = element[0]
        frame = element[1]

        corresponding_frame_found = 0
        for ind in range(num_frames):
            # find the match frame, record corresponding valid points
            if frame_num_strs[ind] == frame:
                corresponding_frame_found = 1
                frame_ind = int(frame_num_strs[ind][-4:])
                # if frame_ind >= 49 or frame_ind <0:
                #     continue
                print('found match frame: (frame that is successfully reconstructed)', frame_num_strs[ind])
                cur_valid_points = frame_points[ind]
                num_pts = cur_valid_points.shape[0]
                # find the location of fruit one-by-one
                for fruit_and_trackid in fruits_and_trackids:

                    cur_fruit_trackid = fruit_and_trackid[2]
                    # bbox is [x,y,w,h]
                    bbox = fruit_and_trackid[1]
                    bbox_area = bbox[2]*bbox[3]
                    # # TODO: new edit: I vectorize here to speed up
                    neighbor_points_three_dim_loc = []
                    fruit_center_position = fruit_and_trackid[0]
                    diff = np.linalg.norm(cur_valid_points[:,:2] - fruit_center_position, axis=1)
                    good_idx = diff < 0.5
                    three_dim_pt_idx_all = cur_valid_points[good_idx,2]


                    for three_dim_pt_idx in three_dim_pt_idx_all:
                        neighbor_points_three_dim_loc.append(three_dim_pts_ind_pos_dict[three_dim_pt_idx])

                    num_neighbor_pts = len(neighbor_points_three_dim_loc)
                    if num_neighbor_pts == 0:
                        total_num_of_fruits_no_corr_3D_point += 1
                        if frame_ind not in num_of_fruits_no_corr_3D_point:
                            num_of_fruits_no_corr_3D_point[frame_ind] = {'fruits_no_3D_pt':1, 'total_fruits':len(fruits_and_trackids)}
                        else:
                            num_of_fruits_no_corr_3D_point[frame_ind]['fruits_no_3D_pt'] += 1
                        continue
                    elif num_neighbor_pts == 1:
                        if np.linalg.norm(cur_valid_points[good_idx,:2] - fruit_center_position) > 0.1:
                            print('the norm of found sfm feature position and tracked fruit center position are larger than 0.1, they should be the same, check their values:',cur_valid_points[good_idx,:2], fruit_center_position)
                    else:
                        print('Multiple sfm features for the same fruit center, check the implementation, found sfm feature position and tracked fruit center position are (should be the same):',cur_valid_points[good_idx,:2], fruit_center_position)
                        false_case += 0.5

                    if num_neighbor_pts != 0:
                        # fruit_3D_pos_bboxes_hist_dict: key is 3D point index, value is a dictionary: {'3Dpos':fruit_3D_loc, 'frame_idx': [frame_ind] (order: small to large), '2Dpos_bbox':fruit}, which contains fruits' 3D position, frame index where it appears (a list of integers) and corresponding frame's 2D_position_and_bbox (a list where each element is another list: [array(x_center, y_center),array(bbox)])
                        # Note: fruit 2D position is based on the Kalman Filter output, not the FRCNN bbox center!!!
                        fruit_3D_loc_instance = neighbor_points_three_dim_loc[0]

                        # This dictonary records the correspondences between track id and its reconstructed 3D points. Every 3D point instance (useful for computing weighted average, may be the same point repeated for multiple times ) will be recorded.
                        if cur_fruit_trackid not in track_id_3D_point_dict:
                            track_id_3D_point_dict[cur_fruit_trackid] = [np.ndarray.tolist(fruit_3D_loc_instance)]
                            fruit_3D_pos_bboxes_hist_dict[cur_fruit_trackid] = {'3Dpos':fruit_3D_loc_instance, 'frame_idx': [frame_ind], '2Dpos_bbox':[fruit_and_trackid[:2]]}
                        else:
                            if np.ndarray.tolist(fruit_3D_loc_instance) not in track_id_3D_point_dict[cur_fruit_trackid]:
                                print('duplicate 3D reconstruction points find for the same fruit track!! Here average them...')
                                duplicate_reconstructed_tracks += 1
                            track_id_3D_point_dict[cur_fruit_trackid].append(np.ndarray.tolist(fruit_3D_loc_instance))
                            x_all = [cur_track_id_3D_point[0] for cur_track_id_3D_point in track_id_3D_point_dict[cur_fruit_trackid]]
                            y_all = [cur_track_id_3D_point[1] for cur_track_id_3D_point in track_id_3D_point_dict[cur_fruit_trackid]]
                            z_all = [cur_track_id_3D_point[2] for cur_track_id_3D_point in track_id_3D_point_dict[cur_fruit_trackid]]
                            cur_track_id_3D_point_avg = [sum(x_all) / float(len(x_all)), sum(y_all) / float(len(y_all)), sum(z_all) / float(len(z_all))]
                            # track_id_3D_point_cur_fruit_trackid_arr = np.array(track_id_3D_point_dict[cur_fruit_trackid])
                            # fruit_3D_loc_weighted_averaged_arr = np.average(track_id_3D_point_cur_fruit_trackid_arr, axis=0)
                            fruit_3D_loc_weighted_averaged = np.array([cur_track_id_3D_point_avg[0], cur_track_id_3D_point_avg[1], cur_track_id_3D_point_avg[2]])
                            fruit_3D_pos_bboxes_hist_dict[cur_fruit_trackid]['3Dpos'] = fruit_3D_loc_weighted_averaged
                            fruit_3D_pos_bboxes_hist_dict[cur_fruit_trackid]['frame_idx'].append(frame_ind)
                            fruit_3D_pos_bboxes_hist_dict[cur_fruit_trackid]['2Dpos_bbox'].append(fruit_and_trackid[:2])


                        # if three_dim_pt_idx_all[0] not in fruit_3D_pos_bboxes_hist_dict:
                        #     fruit_3D_pos_bboxes_hist_dict[three_dim_pt_idx_all[0]] = {'3Dpos':fruit_3D_loc, 'frame_idx': [frame_ind], '2Dpos_bbox':[fruit_and_trackid[:2]]}
                        # else:
                        #     fruit_3D_pos_bboxes_hist_dict[three_dim_pt_idx_all[0]]['frame_idx'].append(frame_ind)
                        #     fruit_3D_pos_bboxes_hist_dict[three_dim_pt_idx_all[0]]['2Dpos_bbox'].append(fruit_and_trackid[:2])


        if corresponding_frame_found == 0:
             print('No corresponding reconstructed frame found!!!!!')

    end_loop = time.time()
    time_period = end_loop - start_loop

    print('number of false case (same feature being projected twice) is:', false_case)
    print('number of duplicate reconstructed tracks is:', duplicate_reconstructed_tracks)
    print('total_num_of_fruits_no_corr_3D_point is',total_num_of_fruits_no_corr_3D_point,'avg_num_of_fruits_no_corr_3D_point is', total_num_of_fruits_no_corr_3D_point / len(num_of_fruits_no_corr_3D_point), '. This should not be too large (around 10 is acceptable)!\n')
    print('total time for finding all fruits location, bbox and history is:', time_period, 'seconds\n')
    # pos_area_fridx_bbox_of_fruits_arr = np.array(pos_area_fridx_bbox_of_fruits)
    # np.savetxt('../generated_docs_this_run/pos_area_fridx_bbox_of_fruits_text.txt',pos_area_fridx_bbox_of_fruits_arr,'%.2f',header='3D positions and areas of fruits(X, Y, Z, bbox area, fruit frame ID, bbox[x,y,w,h], tracking_hist_list)')
    # with open('../generated_docs_this_run/pos_area_fridx_bbox_of_fruits.pkl', 'wb') as output_loc:
    #     pickle.dump(pos_area_fridx_bbox_of_fruits, output_loc)
    # with open('generated_docs_this_run\\frame_num_corr_pos_of_fruits.pkl', 'wb') as output_frame_num:
    #     pickle.dump(frame_num_corr_pos_of_fruits, output_frame_num)

    with open(data_dir_pre +'/generated_docs_this_run/fruit_3D_pos_bboxes_hist_dict.pkl', 'wb') as output_loc:
        pickle.dump(fruit_3D_pos_bboxes_hist_dict, output_loc)

if __name__ == "__main__":
    folder_dir_working_on = glob.glob('/home/sam/Desktop/Fruit-count-dataset/ACFR_RCNN_GT/doing/*')
    if len(folder_dir_working_on) != 1:
        raise Exception('folder_dir_working_on != 1, check data folder!')
    else:
        data_dir_pre = folder_dir_working_on[0]
        print('current data directory:', data_dir_pre)
    extract_landmark_3D_pos_bboxes_hist(data_dir_pre)
